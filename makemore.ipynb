{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMewqgQ2jbIy8Ze9MilgKci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sganguly3000ai/makemore/blob/main/makemore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TTCVE-YosBSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bigram character level language model**"
      ],
      "metadata": {
        "id": "nzTwea-NTw5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import all neccessary packages"
      ],
      "metadata": {
        "id": "i0ccCLvOZNg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import string\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Mga2OWEQUhPh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create reference dictionaries for lookup\n",
        "\n",
        "\n",
        "* Get all the lowercase characters of the English language in List format.\n",
        "Enumerate the list to create a Dictionary of the characters (e.g. 'a': 1 etc) as stoi.stoi is a dictionary that is a cross reference between\n",
        "the characters and their 'assigned' integer values.\n",
        "* Significance of s:i+1.The enumeration starts from 0, but we want it to start from 1.\n",
        "\n",
        "  Original stoi is {'a': 0, 'b': 1, ... , 'z': 26}. We want to shift the keys by 1 such that the resulting dictionary is like {'a': 1, 'b': 2, ..., 'z': 26}.\n",
        "\n",
        "  This shifting along with the addition of a 'special character' explained below will allow the bigram plot to allign in a way that it is easily readable.\n",
        "* Use a special character '.' to be used to signify the starting and ending character of every 'Name' word to be used as parameters ( later in the exercise ) to train this Bigram Character model\n",
        "* The special character '.' is added to stoi with a index value of 0\n",
        "* itos is the dictionary that provides the mapping from integer to character.\n",
        "  itos is stoi with the value and key transposed\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sU6JiMGOZg2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = list(string.ascii_lowercase)\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "zurpq0TjU7Lh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the data ready and train the model\n",
        "\n",
        "*   Prepare a list of common (people) names as variable 'words'. Get it from a data source if possible by downloading and reading it in.\n",
        "\n",
        "*   Initialize a torch.tensor N which will be used to store the counts of how many times one character follows another character in a name.\n",
        "\n",
        "*   Iterate the list of names adding the special character '.' to the start and end of each name.\n",
        "\n",
        "*   Iterate through the characters in the name (starting with the start special character and ending with the end special character) and identify two consecutive characters.\n",
        "*   Convert the two characters (ch1 and ch2) to two integers (ix1 and ix2) by performing a lookup in the stoi dictionary.\n",
        "\n",
        "*   Using the two integers (ix1 and ix2) as row and column index of the tensor N, we increment the increment the value of N[ix1,ix2] by 1.\n",
        "\n",
        "*   Essentially we are recording the count of how many times the character (ch1) appeared before the character (ch2) in all of the names in the dataset to be used as the training data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uVDsAKdTg1rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['sumit','sorit','swapna','suraj','sujit', 'sujoy', 'manoj', 'amit',\n",
        "         'kajol', 'steve', 'andrew','bob', 'cindy', 'ebrahim', 'daku', 'johny',\n",
        "         'timmy', 'david', 'tarun', 'nancy', 'edith', 'jason', 'kyle', 'joseph',\n",
        "         'kimberly', 'emma', 'irene', 'michael', 'scott', 'valentino']\n",
        "N = torch.zeros((27,27) , dtype = torch.int32)\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1,ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    N[ix1,ix2] += 1"
      ],
      "metadata": {
        "id": "JiB8qFt6hJ_1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all required packages\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create dictionaries as character lookup and translation to integer\n",
        "# This is required since strings cannot be stored in tensors\n",
        "\n",
        "chars = list(string.ascii_lowercase)\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "\n",
        "# Create a list of common names. Preferably one should find a dataset of names online\n",
        "\n",
        "words = ['sumit','sorit','swapna','suraj','sujit', 'sujoy', 'manoj', 'amit',\n",
        "         'kajol', 'steve', 'andrew','bob', 'cindy', 'ebrahim', 'daku', 'johny',\n",
        "         'timmy', 'david', 'tarun', 'nancy', 'edith', 'jason', 'kyle', 'joseph',\n",
        "         'kimberly', 'emma', 'irene', 'michael', 'scott', 'valentino']\n",
        "\n",
        "# Tensor N will hold the raw counts of the Bigram\n",
        "\n",
        "N = torch.zeros((27,27) , dtype = torch.int32)\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1,ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    N[ix1,ix2] += 1\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(N, cmap='Reds')\n",
        "\n",
        "for i in range(27):\n",
        "  for j in range(27):\n",
        "    chstr = itos[i] + itos [j]\n",
        "    plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color=\"gray\")\n",
        "    plt.text(j, i, N[i,j].item(), ha=\"center\", va=\"top\", color=\"gray\")\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "QE-aXaCphRwF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}