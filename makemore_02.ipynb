{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFmNzLNUEryAr6DGSYSc57",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sganguly3000ai/makemore/blob/main/makemore_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TTCVE-YosBSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bigram character level language model using neural network MLP**"
      ],
      "metadata": {
        "id": "nzTwea-NTw5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Mga2OWEQUhPh"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#f = open('sample_data/yob1996.txt', encoding=\"utf-8\")\n",
        "names   = np.loadtxt('sample_data/yob1996.txt', delimiter=',', usecols = 0, dtype = str)\n",
        "lnames  = np.char.lower(names)\n",
        "unames  = np.unique(lnames)\n",
        "# for l in f:\n",
        "#   print (l)\n"
      ],
      "metadata": {
        "id": "RHYuhNN7J5I0"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{names} : {lnames}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ND9wHCyM0Qp",
        "outputId": "77000b84-64c2-4306-9bd0-d94000d0367e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Emily' 'Jessica' 'Ashley' ... 'Zishe' 'Zoran' 'Zyler'] : ['emily' 'jessica' 'ashley' ... 'zishe' 'zoran' 'zyler']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names.shape,lnames.shape,unames.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MefcqlWeSOtZ",
        "outputId": "a8b4fc76-a20e-4199-fd54-5cda276e8338"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26426,), (26426,), (24306,))"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "EQhsvMTtST8x",
        "outputId": "94c6b0bb-15fb-4d0e-89c7-07a35c9438e0"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'set' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-af2d2e463c75>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnames1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'set' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "p = Path('./sample_data')\n",
        "\n",
        "\n",
        "# create a list of words or names\n",
        "words = ['sumit','sorit','swapna','suraj','sujit', 'sujoy', 'manoj', 'amit',\n",
        "         'kajol', 'steve', 'andrew','bob', 'cindy', 'ebrahim', 'daku', 'johny',\n",
        "         'timmy', 'david', 'tarun', 'nancy', 'edith', 'jason', 'kyle', 'joseph',\n",
        "         'kimberly', 'emma', 'irene', 'michael', 'scott', 'valentino']\n",
        "# build the vocabulary of characters and mappings to/from integers\n",
        "# '.' is the special character signifying the start or end of a word\n",
        "chars = list(string.ascii_lowercase)\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "zurpq0TjU7Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Num of words = {len(words)}')\n",
        "print(f'Vocabulary = {itos}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oANdVfGRp92M",
        "outputId": "ba58a0a1-4016-4d4c-fd02-b5c88d349e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of words = 30\n",
            "Vocabulary = {1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "X, Y = [],[]\n",
        "num_of_words = 0\n",
        "for w in words:\n",
        "\n",
        "  #print(w)\n",
        "  context = [0] * block_size\n",
        "\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    #print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
        "    context = context[1:] + [ix] #crop and append\n",
        "num_of_words += 1\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)\n",
        "\n",
        "num_of_labels = len(Y)\n"
      ],
      "metadata": {
        "id": "nipzETe2gWC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make it more respectable and lets put the code together"
      ],
      "metadata": {
        "id": "QPcsXErte3dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape # datasets (inputs and labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEY5P6vhmezQ",
        "outputId": "03824d35-256f-43d3-b6ae-fe705ae1279b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([188, 3]), torch.Size([188]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g   =   torch.Generator().manual_seed(2147483647)\n",
        "C   =   torch.randn((27,2), generator = g)\n",
        "W1  =   torch.randn((6,100), generator = g)\n",
        "b1  =   torch.randn((100), generator = g)\n",
        "W2  =   torch.randn((100,27), generator = g)      # 27 possible outputs for 27 lowercase english characters\n",
        "b2  =   torch.randn((27), generator = g)\n",
        "parameters  = [C, W1, b1, W2, b2]"
      ],
      "metadata": {
        "id": "HNTKH4-3pSFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.nelement() for p in parameters)             # number of parameters in total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yef3J0DThUUS",
        "outputId": "45d6cf01-3db5-4334-fb2d-f0d4abecab5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3481"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "RP2Ul3W-p0kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to figure out what learning rate to use\n",
        "# guess a learning rate (one low and one high)\n",
        "# plug in the (guessed) low learning rate and train the model - observe the rate at which the loss is going down\n",
        "# plug in the (guessed) high learning rate and train the model - observe the rate at which the loss is going down\n",
        "# the (guessed) low and high lr should both not make the loss go down fairly quickly\n",
        "# for this particular model it seems like the low and high should be .001 and 1\n",
        "\n",
        "lre = torch.linspace(-3,0,1000)   # create evenly spaced values between -3 and 0\n",
        "lrs = 10**lre                     # taking the exponent gives us a tensor of values in the range 1 and .001\n",
        "\n",
        "# now instead of using the guessed learning rate (lr), we will run the model with each learning rate in lrs\n",
        "# and track the losses for a 1000 iterations of training the model"
      ],
      "metadata": {
        "id": "fP-AvYFDbD2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lri   = []    # used to track the learning rate\n",
        "# lossi = []    # used to track the losses for the given lr\n",
        "\n",
        "for i in range(10000):\n",
        "\n",
        "  # minibatch construct (pluck 31 samples out of the total number of samples randomly\n",
        "\n",
        "  ix = torch.randint(0, X.shape[0], (31,))\n",
        "\n",
        "\n",
        "  # forward pass\n",
        "  emb     = C[X[ix]]                              # shape is 31, 3, 2\n",
        "  h       = torch.tanh(emb.view(-1,6) @ W1 + b1)  # shape is 31, 100\n",
        "  logits  = h @ W2 + b2                           # shape is 31, 27 (27 possible outputs for 27 lowercase english characters)\n",
        "  # counts  = logits.exp()\n",
        "  # probs   = counts / counts.sum(1, keepdims = True)\n",
        "  # loss    = -probs[torch.arange(num_of_labels),Y].log().mean()\n",
        "  loss = F.cross_entropy(logits, Y[ix])\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "  # gradient update\n",
        "  for p in parameters:\n",
        "    #lr        = lrs[i]\n",
        "    p.data   += -0.1 * p.grad\n",
        "\n",
        "\"\"\"\n",
        "    p.data    += -lr * p.grad\n",
        "\n",
        "  # track stats for lr\n",
        "  lri.append(lre[i])\n",
        "  lossi.append(loss.item())\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrALJnR3h-KZ",
        "outputId": "aad6340a-473a-4e97-f7de-568346a2bb8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.43690159916877747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lri,lossi) # looks like 10**-1, which is .1 is a good learning rate"
      ],
      "metadata": {
        "id": "Wich7oHxj6OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, validation and test split\n",
        "# should not run the test data through the model too many times. if you do that the model will start to train on the test data\n",
        "\n",
        "trainsplt = int(len(X)*.8)\n",
        "vsplt     = int(len(X)*.1)\n",
        "testsplt  = int(len(X)) - trainsplt - vsplt\n",
        "xtrain, xv, xtest = [],[],[]\n",
        "xtrain, xv, xtest = torch.split(X, (trainsplt,vsplt,testsplt))\n",
        "ytrain, yv, ytest = [],[],[]\n",
        "ytrain, yv, ytest = torch.split(Y, (trainsplt,vsplt,testsplt))"
      ],
      "metadata": {
        "id": "k4oGbTuztJ00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f'{ytrain}\\n{ytrain.shape}\\n{yv}\\n{yv.shape}\\n{ytest}\\n{ytest.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ony72OUou9dS",
        "outputId": "e601d232-afed-4b88-ea80-8e9c90682820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([19, 21, 13,  9, 20,  0, 19, 15, 18,  9, 20,  0, 19, 23,  1, 16, 14,  1,\n",
            "         0, 19, 21, 18,  1, 10,  0, 19, 21, 10,  9, 20,  0, 19, 21, 10, 15, 25,\n",
            "         0, 13,  1, 14, 15, 10,  0,  1, 13,  9, 20,  0, 11,  1, 10, 15, 12,  0,\n",
            "        19, 20,  5, 22,  5,  0,  1, 14,  4, 18,  5, 23,  0,  2, 15,  2,  0,  3,\n",
            "         9, 14,  4, 25,  0,  5,  2, 18,  1,  8,  9, 13,  0,  4,  1, 11, 21,  0,\n",
            "        10, 15,  8, 14, 25,  0, 20,  9, 13, 13, 25,  0,  4,  1, 22,  9,  4,  0,\n",
            "        20,  1, 18, 21, 14,  0, 14,  1, 14,  3, 25,  0,  5,  4,  9, 20,  8,  0,\n",
            "        10,  1, 19, 15, 14,  0, 11, 25, 12,  5,  0, 10, 15, 19,  5, 16,  8,  0,\n",
            "        11,  9, 13,  2,  5, 18])\n",
            "torch.Size([150])\n",
            "tensor([12, 25,  0,  5, 13, 13,  1,  0,  9, 18,  5, 14,  5,  0, 13,  9,  3,  8])\n",
            "torch.Size([18])\n",
            "tensor([ 1,  5, 12,  0, 19,  3, 15, 20, 20,  0, 22,  1, 12,  5, 14, 20,  9, 14,\n",
            "        15,  0])\n",
            "torch.Size([20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v[0],X[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLdzOdT83-Rp",
        "outputId": "736ac8fb-c2d5-4fb8-b180-7b624db48e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([15, 18,  9]), tensor([15, 18,  9]))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}