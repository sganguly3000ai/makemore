{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "82IvTDD2Dpsn"
      ],
      "authorship_tag": "ABX9TyMtB7xwfVNlRIpKa/zv6oA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sganguly3000ai/makemore/blob/main/makemore_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TTCVE-YosBSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bigram character level language model using neural network**"
      ],
      "metadata": {
        "id": "nzTwea-NTw5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Mga2OWEQUhPh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = list(string.ascii_lowercase)\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "zurpq0TjU7Lh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['sumit','sorit','swapna','suraj','sujit', 'sujoy', 'manoj', 'amit',\n",
        "         'kajol', 'steve', 'andrew','bob', 'cindy', 'ebrahim', 'daku', 'johny',\n",
        "         'timmy', 'david', 'tarun', 'nancy', 'edith', 'jason', 'kyle', 'joseph',\n",
        "         'kimberly', 'emma', 'irene', 'michael', 'scott', 'valentino']\n",
        "xs, ys = [], []\n",
        "N = torch.zeros((27,27) , dtype = torch.int32)\n",
        "for w in words[:5]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1,ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    print (ch1, ch2)\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs) # inputs\n",
        "ys = torch.tensor(ys) # labels\n",
        "num = xs.nelement()   # keeping track of how many bigrams\n",
        "print('number of examples or inputs: ', num)\n",
        "\n",
        "\"\"\"\n",
        "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "                INITIALIZE THE NEURAL NETWORK WITH 27 NEURON IN 1 LAYER\n",
        "\n",
        "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# RANDOMLY INITIALIZE 27 NEURONS' WEIGHTS. EACH NEURON RECEIVES 27 INPUTS\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "\"\"\"\n",
        "IMPORTANT TO SET THE requires_grad=True : SO THAT PYTORCH CAN KEEP TRACK OF THE GRADIENTS OF W\n",
        "\"\"\"\n",
        "\n",
        "# getting random numbers from a normal distribution\n",
        "W = torch.randn((27,27), generator=g, requires_grad=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nipzETe2gWC2",
        "outputId": "3f951a33-c45f-40c9-dac1-1b42629447c6"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". s\n",
            "s u\n",
            "u m\n",
            "m i\n",
            "i t\n",
            "t .\n",
            ". s\n",
            "s o\n",
            "o r\n",
            "r i\n",
            "i t\n",
            "t .\n",
            ". s\n",
            "s w\n",
            "w a\n",
            "a p\n",
            "p n\n",
            "n a\n",
            "a .\n",
            ". s\n",
            "s u\n",
            "u r\n",
            "r a\n",
            "a j\n",
            "j .\n",
            ". s\n",
            "s u\n",
            "u j\n",
            "j i\n",
            "i t\n",
            "t .\n",
            "number of examples or inputs:  31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.shape\n",
        "xenc = F.one_hot(xs,num_classes=27).float()\n",
        "logits = xenc @ W\n",
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv2xhNAXzk6X",
        "outputId": "b32ffd5d-e65d-450e-9f69-8a54b77600d9"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([188, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100000):\n",
        "  \"\"\"\n",
        "  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "                                      FORWARD PASS\n",
        "                                    GRADIENT DESCENT\n",
        "\n",
        "  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # cannot pass just one integer as an input to a neural network but can pass\n",
        "  # vectors\n",
        "  # thats why using one hot encoding to generate a tensor represented by 1\n",
        "  # at the index represented by the xs integer\n",
        "\n",
        "  # should not pass in vectors of dtype as int, need to convert xenc to float\n",
        "\n",
        "  xenc = F.one_hot(xs,num_classes=27).float() #inputs to the network: one hot encoding\n",
        "  # plt.imshow(xenc)  uncomment to visualize in a plot\n",
        "\n",
        "  # multiplying to get the logits from the neurons\n",
        "  # feeding in all 6 inputs simultaneously into 27 neurons in layer 1\n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = logits.exp() # equivalent to the N tensor we used in makemore where we were just counting the bigrams\n",
        "  probs = counts / counts.sum(1, keepdims = True) # probabilities for next character (of 27 characters)\n",
        "\n",
        "  # btw: the last 2 lines here are together called a 'softmax'\n",
        "\n",
        "  \"\"\"\n",
        "  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "      CALCULATING THE LOSS - USING NEGATIVE LOG LIKELIHOOD TO CALCULATE LOSS SINCE THIS IS CLASSIFICATION\n",
        "\n",
        "                IF THIS WAS REGRESSION WE WOULD USE MEAN SQUARED ERROR TO CALCULATE LOSS\n",
        "\n",
        "  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "  plucking the values of the probabilities for 6 indices corresponding to the labels\n",
        "  from the probs tensor (since there are 6 labels)\n",
        "  \"\"\"\n",
        "\n",
        "  loss = -probs[torch.arange(num), ys].log().mean()\n",
        "  \"\"\"\n",
        "  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "                                    BACKWARD PASS\n",
        "\n",
        "\n",
        "                                WHAT DOES backward() DO?\n",
        "\n",
        "    pytorch does a backward pass through the neural network starting at the loss node\n",
        "    pytorch keeps track of the gradients which are calculated by performing the derivatives\n",
        "    at each node\n",
        "\n",
        "  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "  \"\"\"\n",
        "# SETTING GRADIENTS OF THE WEIGHTS TO ZERO OR NONE\n",
        "\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  \"\"\"\n",
        "  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "                                    UPDATE W\n",
        "\n",
        "\n",
        "                                WHAT DOES backward() DO?\n",
        "\n",
        "    pytorch does a backward pass through the neural network starting at the loss node\n",
        "    pytorch keeps track of the gradients which are calculated by performing the derivatives\n",
        "    at each node\n",
        "    we update the weights (in the negative direction of the gradients) with a learning factor\n",
        "    multiplied by the gradient\n",
        "\n",
        "  +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "  \"\"\"\n",
        "  W.data += -.01 * W.grad"
      ],
      "metadata": {
        "id": "utlsLJ3Sgtju"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbVyRQdP2maf",
        "outputId": "68d9450f-afed-47fd-e4b1-6bff649720e7"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.47739189863204956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhqYz7Jg0UwX",
        "outputId": "6e42fa5d-73ce-4721-8315-564321f584bd"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETXGo1tu5TXY",
        "outputId": "91a1c917-7e93-43e1-e1d4-d470d4c074ab"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.0387e-05, 1.2137e-05, 1.4665e-05, 5.4416e-06, 1.9284e-05, 1.4635e-05,\n",
              "        3.5300e-06, 2.5153e-05, 1.6116e-05, 3.1871e-05, 9.8211e-06, 2.9090e-05,\n",
              "        1.1164e-05, 1.0174e-05, 4.4541e-05, 9.3975e-05, 5.0209e-05, 3.2678e-06,\n",
              "        2.6647e-05, 9.9870e-01, 3.3867e-05, 1.3154e-05, 3.7704e-06, 2.2124e-05,\n",
              "        1.4107e-05, 8.0990e-05, 7.9331e-05, 8.1644e-06, 4.8511e-06, 1.9571e-05,\n",
              "        5.5916e-06, 2.7760e-05, 1.5722e-05, 4.2685e-05, 7.2105e-06, 6.8890e-06,\n",
              "        2.7372e-06, 4.1047e-05, 4.8246e-06, 4.0039e-05, 6.1989e-06, 1.2194e-05,\n",
              "        1.0969e-05, 2.0065e-05, 4.3762e-06, 3.7460e-05, 2.4982e-05, 2.2312e-05,\n",
              "        1.5762e-05, 2.9223e-06, 1.6640e-05, 2.9466e-05, 2.3884e-05, 5.1169e-06,\n",
              "        1.7111e-05, 5.9906e-06, 2.0889e-05, 2.2588e-05, 6.5089e-06, 7.3421e-06,\n",
              "        1.6925e-05, 1.2424e-05, 5.7653e-06, 3.5657e-06],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.multinomial(probs[4], num_samples=27, replacement=True, generator=g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NLtbhNUjUll",
        "outputId": "4510ace0-43ae-4c7b-be04-745ca67154e7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "        20, 20, 20, 20, 20, 20, 20, 20, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "                     VISUALIZING WHERE THE LOSS IS COMING FROM\n",
        "\n",
        "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "nlls = torch.zeros(6) # negetive log likelihood\n",
        "\n",
        "for i in range(6):\n",
        "  # i-th bigram:\n",
        "  x = xs[i].item() # input character index\n",
        "  y = ys[i].item() # label character index\n",
        "  print('================================================================\\n')\n",
        "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
        "  print('input to the neural net:', x)\n",
        "  print('output probabilities from the neural net:', probs[i])\n",
        "  print('label (actual next character):', y)\n",
        "  p = probs[i, y]\n",
        "  print('probability assigned by the network to the correct character:', p.item())\n",
        "  logp = torch.log(p)\n",
        "  print('log likelihood:', logp.item())\n",
        "  nll = -logp\n",
        "  print(f'negative log likelihood: {nll.item()} \\n')\n",
        "  nlls[i] = nll\n",
        "  print('================================================================\\n')\n",
        "  print(f'average negative log likelihood after each bigram, i.e. loss = {nlls.mean().item()} \\n')\n",
        "  print('================================================================\\n')\n",
        "\n",
        "print(f'average negative log likelihood after all inputs, i.e. loss = {nlls.mean().item()} \\n')"
      ],
      "metadata": {
        "id": "8Ak56SO5hnvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFg8nnipljmy",
        "outputId": "e02a048c-fa8b-42d9-95c9-e36d594aee30"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 19, 21, 13,  9, 20,  0, 19, 15, 18,  9, 20,  0, 19, 23,  1, 16, 14,\n",
              "         1,  0, 19, 21, 18,  1, 10,  0, 19, 21, 10,  9, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling\n",
        "\n",
        "\n",
        "*   torch.multinomial generates sample integer based on probabilities that are fed to the function\n",
        "\n",
        "*   These integers are the index to the probability tensor P\n",
        "\n",
        "\n",
        "*   The out list is being appended with the character equivalent of the index number thst the model is generating based on its training. The generation stops when the index value generated is 0 (indicating the end of a generated name).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XV7IWzpcrjxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "print (f'GENERATED NAMES BY THE BIGRAM MODEL')\n",
        "print (f'===================================\\n')\n",
        "for i in range(num):\n",
        "  p = probs[i]\n",
        "  ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "  print ('Predicted character= ' , itos[ix])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSj9gg15Ryfy",
        "outputId": "a6600925-633f-41d1-bf9b-3466d2df2d31"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED NAMES BY THE BIGRAM MODEL\n",
            "===================================\n",
            "\n",
            "Predicted character=  s\n",
            "Predicted character=  u\n",
            "Predicted character=  m\n",
            "Predicted character=  i\n",
            "Predicted character=  t\n",
            "Predicted character=  .\n",
            "Predicted character=  s\n",
            "Predicted character=  u\n",
            "Predicted character=  r\n",
            "Predicted character=  i\n",
            "Predicted character=  t\n",
            "Predicted character=  .\n",
            "Predicted character=  s\n",
            "Predicted character=  o\n",
            "Predicted character=  a\n",
            "Predicted character=  p\n",
            "Predicted character=  n\n",
            "Predicted character=  a\n",
            "Predicted character=  p\n",
            "Predicted character=  s\n",
            "Predicted character=  o\n",
            "Predicted character=  j\n",
            "Predicted character=  a\n",
            "Predicted character=  .\n",
            "Predicted character=  i\n",
            "Predicted character=  s\n",
            "Predicted character=  w\n",
            "Predicted character=  m\n",
            "Predicted character=  i\n",
            "Predicted character=  t\n",
            "Predicted character=  .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RrU8XOW6ry_",
        "outputId": "29cbbd79-4587-47ea-f113-c3bfaa735ca8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Find the loss"
      ],
      "metadata": {
        "id": "mUneD6K0_d-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1,ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    prob = P[ix1,ix2]\n",
        "    logprob = torch.log(prob)\n",
        "    log_likelihood += logprob\n",
        "    n += 1\n",
        "    print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
        "\n",
        "print (f'{log_likelihood=}')\n",
        "#negetive log_likelihood\n",
        "nll = -log_likelihood\n",
        "print (f'{nll=}')\n",
        "print (f'{nll/n}') # loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxHNOv8UvGSZ",
        "outputId": "cc6ddc37-0029-46c4-d01d-1aac9de5e52c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".s: 0.2667 -1.3218\n",
            "su: 0.4000 -0.9163\n",
            "um: 0.1667 -1.7918\n",
            "mi: 0.3000 -1.2040\n",
            "it: 0.3846 -0.9555\n",
            "t.: 0.4545 -0.7885\n",
            ".s: 0.2667 -1.3218\n",
            "so: 0.2000 -1.6094\n",
            "or: 0.1000 -2.3026\n",
            "ri: 0.1429 -1.9459\n",
            "it: 0.3846 -0.9555\n",
            "t.: 0.4545 -0.7885\n",
            ".s: 0.2667 -1.3218\n",
            "sw: 0.1000 -2.3026\n",
            "wa: 0.5000 -0.6931\n",
            "ap: 0.0625 -2.7726\n",
            "pn: 0.5000 -0.6931\n",
            "na: 0.1667 -1.7918\n",
            "a.: 0.1250 -2.0794\n",
            ".s: 0.2667 -1.3218\n",
            "su: 0.4000 -0.9163\n",
            "ur: 0.1667 -1.7918\n",
            "ra: 0.2857 -1.2528\n",
            "aj: 0.1250 -2.0794\n",
            "j.: 0.2500 -1.3863\n",
            ".s: 0.2667 -1.3218\n",
            "su: 0.4000 -0.9163\n",
            "uj: 0.3333 -1.0986\n",
            "ji: 0.1250 -2.0794\n",
            "it: 0.3846 -0.9555\n",
            "t.: 0.4545 -0.7885\n",
            ".s: 0.2667 -1.3218\n",
            "su: 0.4000 -0.9163\n",
            "uj: 0.3333 -1.0986\n",
            "jo: 0.5000 -0.6931\n",
            "oy: 0.1000 -2.3026\n",
            "y.: 0.8571 -0.1542\n",
            ".m: 0.0667 -2.7081\n",
            "ma: 0.2000 -1.6094\n",
            "an: 0.1875 -1.6740\n",
            "no: 0.1667 -1.7918\n",
            "oj: 0.1000 -2.3026\n",
            "j.: 0.2500 -1.3863\n",
            ".a: 0.0667 -2.7081\n",
            "am: 0.0625 -2.7726\n",
            "mi: 0.3000 -1.2040\n",
            "it: 0.3846 -0.9555\n",
            "t.: 0.4545 -0.7885\n",
            ".k: 0.1000 -2.3026\n",
            "ka: 0.2500 -1.3863\n",
            "aj: 0.1250 -2.0794\n",
            "jo: 0.5000 -0.6931\n",
            "ol: 0.1000 -2.3026\n",
            "l.: 0.4000 -0.9163\n",
            ".s: 0.2667 -1.3218\n",
            "st: 0.1000 -2.3026\n",
            "te: 0.0909 -2.3979\n",
            "ev: 0.0769 -2.5649\n",
            "ve: 0.3333 -1.0986\n",
            "e.: 0.2308 -1.4663\n",
            ".a: 0.0667 -2.7081\n",
            "an: 0.1875 -1.6740\n",
            "nd: 0.1667 -1.7918\n",
            "dr: 0.1667 -1.7918\n",
            "re: 0.2857 -1.2528\n",
            "ew: 0.0769 -2.5649\n",
            "w.: 0.5000 -0.6931\n",
            ".b: 0.0333 -3.4012\n",
            "bo: 0.2500 -1.3863\n",
            "ob: 0.1000 -2.3026\n",
            "b.: 0.2500 -1.3863\n",
            ".c: 0.0333 -3.4012\n",
            "ci: 0.2500 -1.3863\n",
            "in: 0.1538 -1.8718\n",
            "nd: 0.1667 -1.7918\n",
            "dy: 0.1667 -1.7918\n",
            "y.: 0.8571 -0.1542\n",
            ".e: 0.1000 -2.3026\n",
            "eb: 0.0769 -2.5649\n",
            "br: 0.2500 -1.3863\n",
            "ra: 0.2857 -1.2528\n",
            "ah: 0.0625 -2.7726\n",
            "hi: 0.2000 -1.6094\n",
            "im: 0.2308 -1.4663\n",
            "m.: 0.1000 -2.3026\n",
            ".d: 0.0667 -2.7081\n",
            "da: 0.3333 -1.0986\n",
            "ak: 0.0625 -2.7726\n",
            "ku: 0.2500 -1.3863\n",
            "u.: 0.1667 -1.7918\n",
            ".j: 0.1000 -2.3026\n",
            "jo: 0.5000 -0.6931\n",
            "oh: 0.1000 -2.3026\n",
            "hn: 0.2000 -1.6094\n",
            "ny: 0.0833 -2.4849\n",
            "y.: 0.8571 -0.1542\n",
            ".t: 0.0667 -2.7081\n",
            "ti: 0.1818 -1.7047\n",
            "im: 0.2308 -1.4663\n",
            "mm: 0.2000 -1.6094\n",
            "my: 0.1000 -2.3026\n",
            "y.: 0.8571 -0.1542\n",
            ".d: 0.0667 -2.7081\n",
            "da: 0.3333 -1.0986\n",
            "av: 0.0625 -2.7726\n",
            "vi: 0.3333 -1.0986\n",
            "id: 0.0769 -2.5649\n",
            "d.: 0.1667 -1.7918\n",
            ".t: 0.0667 -2.7081\n",
            "ta: 0.0909 -2.3979\n",
            "ar: 0.0625 -2.7726\n",
            "ru: 0.1429 -1.9459\n",
            "un: 0.1667 -1.7918\n",
            "n.: 0.1667 -1.7918\n",
            ".n: 0.0333 -3.4012\n",
            "na: 0.1667 -1.7918\n",
            "an: 0.1875 -1.6740\n",
            "nc: 0.0833 -2.4849\n",
            "cy: 0.2500 -1.3863\n",
            "y.: 0.8571 -0.1542\n",
            ".e: 0.1000 -2.3026\n",
            "ed: 0.0769 -2.5649\n",
            "di: 0.1667 -1.7918\n",
            "it: 0.3846 -0.9555\n",
            "th: 0.0909 -2.3979\n",
            "h.: 0.4000 -0.9163\n",
            ".j: 0.1000 -2.3026\n",
            "ja: 0.1250 -2.0794\n",
            "as: 0.0625 -2.7726\n",
            "so: 0.2000 -1.6094\n",
            "on: 0.1000 -2.3026\n",
            "n.: 0.1667 -1.7918\n",
            ".k: 0.1000 -2.3026\n",
            "ky: 0.2500 -1.3863\n",
            "yl: 0.1429 -1.9459\n",
            "le: 0.4000 -0.9163\n",
            "e.: 0.2308 -1.4663\n",
            ".j: 0.1000 -2.3026\n",
            "jo: 0.5000 -0.6931\n",
            "os: 0.1000 -2.3026\n",
            "se: 0.1000 -2.3026\n",
            "ep: 0.0769 -2.5649\n",
            "ph: 0.5000 -0.6931\n",
            "h.: 0.4000 -0.9163\n",
            ".k: 0.1000 -2.3026\n",
            "ki: 0.2500 -1.3863\n",
            "im: 0.2308 -1.4663\n",
            "mb: 0.1000 -2.3026\n",
            "be: 0.2500 -1.3863\n",
            "er: 0.0769 -2.5649\n",
            "rl: 0.1429 -1.9459\n",
            "ly: 0.2000 -1.6094\n",
            "y.: 0.8571 -0.1542\n",
            ".e: 0.1000 -2.3026\n",
            "em: 0.0769 -2.5649\n",
            "mm: 0.2000 -1.6094\n",
            "ma: 0.2000 -1.6094\n",
            "a.: 0.1250 -2.0794\n",
            ".i: 0.0333 -3.4012\n",
            "ir: 0.0769 -2.5649\n",
            "re: 0.2857 -1.2528\n",
            "en: 0.1538 -1.8718\n",
            "ne: 0.0833 -2.4849\n",
            "e.: 0.2308 -1.4663\n",
            ".m: 0.0667 -2.7081\n",
            "mi: 0.3000 -1.2040\n",
            "ic: 0.0769 -2.5649\n",
            "ch: 0.2500 -1.3863\n",
            "ha: 0.2000 -1.6094\n",
            "ae: 0.0625 -2.7726\n",
            "el: 0.0769 -2.5649\n",
            "l.: 0.4000 -0.9163\n",
            ".s: 0.2667 -1.3218\n",
            "sc: 0.1000 -2.3026\n",
            "co: 0.2500 -1.3863\n",
            "ot: 0.1000 -2.3026\n",
            "tt: 0.0909 -2.3979\n",
            "t.: 0.4545 -0.7885\n",
            ".v: 0.0333 -3.4012\n",
            "va: 0.3333 -1.0986\n",
            "al: 0.0625 -2.7726\n",
            "le: 0.4000 -0.9163\n",
            "en: 0.1538 -1.8718\n",
            "nt: 0.0833 -2.4849\n",
            "ti: 0.1818 -1.7047\n",
            "in: 0.1538 -1.8718\n",
            "no: 0.1667 -1.7918\n",
            "o.: 0.1000 -2.3026\n",
            "log_likelihood=tensor(-331.6241)\n",
            "nll=tensor(331.6241)\n",
            "1.7639577388763428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c-ghOCYODiIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check the probability and loss for any given word"
      ],
      "metadata": {
        "id": "82IvTDD2Dpsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "for w in ['steve']:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1,ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    prob = P[ix1,ix2]\n",
        "    logprob = torch.log(prob)\n",
        "    log_likelihood += logprob\n",
        "    n += 1\n",
        "    print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
        "\n",
        "print (f'{log_likelihood=}')\n",
        "#negetive log_likelihood\n",
        "nll = -log_likelihood\n",
        "print (f'{nll=}')\n",
        "print (f'{nll/n}') # loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5FVNn9hD2Mt",
        "outputId": "0c0811c8-3f32-41d5-942b-6af6f3d97501"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".s: 0.2667 -1.3218\n",
            "st: 0.1000 -2.3026\n",
            "te: 0.0909 -2.3979\n",
            "ev: 0.0769 -2.5649\n",
            "ve: 0.3333 -1.0986\n",
            "e.: 0.2308 -1.4663\n",
            "log_likelihood=tensor(-11.1521)\n",
            "nll=tensor(11.1521)\n",
            "1.858689308166504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model smoothing\n",
        "\n",
        "\n",
        "*   The loss is infinite for some names that the model has 0 probability of predicting\n",
        "*   In order to alleviate this infinite loss this model can be smoothed out by adding some positive values to the probability\n",
        "\n"
      ],
      "metadata": {
        "id": "spfvdu2HFVY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# here we are adding 1 to every bigram count\n",
        "# any number can be added\n",
        "P = (N+1).float()\n",
        "D = P.sum(1, keepdim = True)\n",
        "# If the sum of the items in the row is 0, then set it to 1 to avoid division by 0\n",
        "for d in D:\n",
        "  if d[0]==0.0:\n",
        "    d[0]= 1.0\n",
        "P /= D\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "print (f'GENERATED NAMES BY THE BIGRAM MODEL')\n",
        "print (f'===================================\\n')\n",
        "for i in range(10):\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    p = P[ix]\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print (''.join(out))\n",
        "\n",
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "for w in ['chico']:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1,ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    prob = P[ix1,ix2]\n",
        "    logprob = torch.log(prob)\n",
        "    log_likelihood += logprob\n",
        "    n += 1\n",
        "    print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
        "\n",
        "print (f'{log_likelihood=}')\n",
        "#negetive log_likelihood\n",
        "nll = -log_likelihood\n",
        "print (f'{nll=}')\n",
        "print (f'{nll/n}') # loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC_wb9sSFbX3",
        "outputId": "f5821ad4-ea23-40b8-cd8d-f68e5cbac380"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATED NAMES BY THE BIGRAM MODEL\n",
            "===================================\n",
            "\n",
            "juwjdvditkaqaz.\n",
            "p.\n",
            "cfqywacny.\n",
            "kuitrltohcogsjgwzvudahntauy.\n",
            "bilevhajkdbdainrwimbl.\n",
            "snjyinaylaftezffvmumthyfodtumj.\n",
            "pfytsuwjhruanq.\n",
            "core.\n",
            "ysezocfky.\n",
            "jabdywebfmiifmwyfin.\n",
            ".c: 0.0351 -3.3499\n",
            "ch: 0.0645 -2.7408\n",
            "hi: 0.0625 -2.7726\n",
            "ic: 0.0500 -2.9957\n",
            "co: 0.0645 -2.7408\n",
            "o.: 0.0541 -2.9178\n",
            "log_likelihood=tensor(-17.5177)\n",
            "nll=tensor(17.5177)\n",
            "2.9196126461029053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete model code"
      ],
      "metadata": {
        "id": "NatBccCu20-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all required packages\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create dictionaries as character lookup and translation to integer\n",
        "# This is required since strings cannot be stored in tensors\n",
        "\n",
        "chars = list(string.ascii_lowercase)\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "\n",
        "# Create a list of common names. Preferably one should find a dataset of names online\n",
        "\n",
        "words = ['sumit','sorit','swapna','suraj','sujit', 'sujoy', 'manoj', 'amit',\n",
        "         'kajol', 'steve', 'andrew','bob', 'cindy', 'ebrahim', 'daku', 'johny',\n",
        "         'timmy', 'david', 'tarun', 'nancy', 'edith', 'jason', 'kyle', 'joseph',\n",
        "         'kimberly', 'emma', 'irene', 'michael', 'scott', 'valentino']\n",
        "\n",
        "# Tensor N will hold the raw counts of the Bigram\n",
        "\n",
        "N = torch.zeros((27,27) , dtype = torch.int32)\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1,ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    N[ix1,ix2] += 1\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(N, cmap='Reds')\n",
        "\n",
        "for i in range(27):\n",
        "  for j in range(27):\n",
        "    chstr = itos[i] + itos [j]\n",
        "    plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color=\"gray\")\n",
        "    plt.text(j, i, N[i,j].item(), ha=\"center\", va=\"top\", color=\"gray\")\n",
        "plt.axis('off')\n",
        "\n",
        "P = N.float()\n",
        "D = P.sum(1, keepdim = True)\n",
        "# If the sum of the items in the row is 0, then set it to 1 to avoid division by 0\n",
        "for d in D:\n",
        "  if d[0]==0.0:\n",
        "    d[0]= 1.0\n",
        "P /= D\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "print (f'GENERATED NAMES BY THE BIGRAM MODEL')\n",
        "print (f'===================================\\n')\n",
        "for i in range(10):\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    p = P[ix]\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print (''.join(out))\n",
        "\n",
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1,ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    prob = P[ix1,ix2]\n",
        "    logprob = torch.log(prob)\n",
        "    log_likelihood += logprob\n",
        "    n += 1\n",
        "    print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
        "\n",
        "print (f'{log_likelihood=}')\n",
        "#negetive log_likelihood\n",
        "nll = -log_likelihood\n",
        "print (f'{nll=}')\n",
        "print (f'{nll/n}') # loss"
      ],
      "metadata": {
        "id": "QE-aXaCphRwF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}